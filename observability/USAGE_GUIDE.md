# ğŸ“Š HÆ°á»›ng dáº«n Sá»­ dá»¥ng Observability Stack

> **TÃ i liá»‡u:** HÆ°á»›ng dáº«n chi tiáº¿t sá»­ dá»¥ng Grafana, query metrics/logs/traces, táº¡o dashboards, vÃ  troubleshooting  
> **MÃ´i trÆ°á»ng:** Azure Kubernetes Service (AKS)  
> **Cáº­p nháº­t:** November 2025

---

## ğŸ“‹ Má»¥c lá»¥c

1. [Truy cáº­p Grafana](#-truy-cáº­p-grafana)
2. [Sá»­ dá»¥ng Metrics (Prometheus)](#-sá»­-dá»¥ng-metrics-prometheus)
3. [Sá»­ dá»¥ng Logs (Loki)](#-sá»­-dá»¥ng-logs-loki)
4. [Sá»­ dá»¥ng Traces (Tempo)](#-sá»­-dá»¥ng-traces-tempo)
5. [Táº¡o Custom Dashboards](#-táº¡o-custom-dashboards)
6. [Alert Management](#-alert-management)
7. [Troubleshooting vá»›i Observability](#-troubleshooting-vá»›i-observability)
8. [Best Practices](#-best-practices)

---

## ğŸŒ Truy cáº­p Grafana

### URL vÃ  Credentials

```
URL: https://grafana.longops.io.vn
Username: admin
Password: Admin@123456
```

**âš ï¸ QUAN TRá»ŒNG:** Äá»•i password ngay sau láº§n Ä‘Äƒng nháº­p Ä‘áº§u tiÃªn!

```
1. Login â†’ Admin (gÃ³c pháº£i) â†’ Profile
2. Tab "Change Password"
3. Nháº­p password má»›i
4. Save
```

### Hoáº·c Port-Forward (Náº¿u chÆ°a setup DNS)

```powershell
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Truy cáº­p: http://localhost:3000
```

### Kiá»ƒm tra Datasources

```
1. Configuration (âš™ï¸) â†’ Data Sources
2. Verify 3 datasources:
   âœ… Prometheus (default) - http://prometheus-kube-prometheus-prometheus:9090
   âœ… Loki - http://loki-gateway:80
   âœ… Tempo - http://tempo:3100
```

**Test datasources:**
- Click vÃ o tá»«ng datasource â†’ "Save & Test"
- Pháº£i tháº¥y: âœ… "Data source is working"

---

## ğŸ“ˆ Sá»­ dá»¥ng Metrics (Prometheus)

### 1. Explore Metrics

**Navigation:** Explore (ğŸ§­) â†’ Chá»n "Prometheus" á»Ÿ dropdown

### 2. Basic Queries

#### 2.1. CPU Usage cá»§a táº¥t cáº£ pods

```promql
# CPU usage (cores)
sum(rate(container_cpu_usage_seconds_total{namespace="ftm-dev"}[5m])) by (pod)

# CPU usage (%)
sum(rate(container_cpu_usage_seconds_total{namespace="ftm-dev"}[5m])) by (pod) 
/ sum(container_spec_cpu_quota{namespace="ftm-dev"} / container_spec_cpu_period{namespace="ftm-dev"}) by (pod) 
* 100
```

**Giáº£i thÃ­ch:**
- `rate([5m])`: TÃ­nh average trong 5 phÃºt
- `by (pod)`: Group theo pod name
- Click "Run Query" â†’ Tháº¥y graph

#### 2.2. Memory Usage

```promql
# Memory working set (Ä‘ang dÃ¹ng thá»±c táº¿)
sum(container_memory_working_set_bytes{namespace="ftm-dev"}) by (pod)

# Memory limit
sum(container_spec_memory_limit_bytes{namespace="ftm-dev"}) by (pod)

# Memory usage (%)
sum(container_memory_working_set_bytes{namespace="ftm-dev"}) by (pod)
/ sum(container_spec_memory_limit_bytes{namespace="ftm-dev"}) by (pod)
* 100
```

#### 2.3. Pod Restart Count

```promql
# Total restarts
sum(kube_pod_container_status_restarts_total{namespace="ftm-dev"}) by (pod)

# Restart rate (restarts per minute)
rate(kube_pod_container_status_restarts_total{namespace="ftm-dev"}[5m]) * 60
```

#### 2.4. HTTP Request Rate (Backend)

```promql
# Total requests per second
sum(rate(http_requests_total{namespace="ftm-dev"}[5m])) by (endpoint)

# 5xx error rate
sum(rate(http_requests_total{namespace="ftm-dev",status=~"5.."}[5m])) by (endpoint)
```

**âš ï¸ Note:** Backend pháº£i export metrics nÃ y. Xem pháº§n "Instrumentation" bÃªn dÆ°á»›i.

#### 2.5. Node Resources

```promql
# Node CPU usage (%)
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Node Memory usage (%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# Node Disk usage (%)
100 - ((node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100)
```

### 3. Query Builder vs Code Mode

**Query Builder (Recommended cho beginners):**
- Click "Metrics browser" â†’ Browse available metrics
- Select labels â†’ Auto-generate query

**Code Mode (Advanced):**
- Type PromQL directly
- Use autocomplete (Ctrl+Space)
- See [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)

### 4. Time Range vÃ  Refresh

```
GÃ³c pháº£i trÃªn:
- Time range: Last 1 hour / 6 hours / 24 hours / 7 days
- Refresh: Auto-refresh every 5s / 10s / 30s / 1m
```

### 5. Visualizations

Sau khi query, switch visualization:
- **Graph**: Time series line chart
- **Table**: Tabular data
- **Stat**: Single number
- **Gauge**: Progress bar

---

## ğŸ“ Sá»­ dá»¥ng Logs (Loki)

### 1. Explore Logs

**Navigation:** Explore (ğŸ§­) â†’ Chá»n "Loki" á»Ÿ dropdown

### 2. Basic Log Queries (LogQL)

#### 2.1. All logs from namespace

```logql
{namespace="ftm-dev"}
```

#### 2.2. Logs from specific pod

```logql
{namespace="ftm-dev", pod="ftm-backend-7897b5c994-xxxxx"}
```

**Tip:** DÃ¹ng autocomplete - gÃµ `{` vÃ  nháº¥n Ctrl+Space

#### 2.3. Logs from container

```logql
{namespace="ftm-dev", container="backend"}
```

#### 2.4. Filter logs by content

```logql
# Contains "error" (case-insensitive)
{namespace="ftm-dev"} |~ "(?i)error"

# Contains "exception" or "error"
{namespace="ftm-dev"} |~ "exception|error"

# Does NOT contain "health"
{namespace="ftm-dev"} != "health"

# Starts with "[Error]"
{namespace="ftm-dev"} |~ "^\\[Error\\]"
```

**LogQL Operators:**
- `|=`: Contains (exact)
- `!=`: Does not contain
- `|~`: Regex match
- `!~`: Regex does not match

#### 2.5. Parse JSON logs

```logql
# If backend logs JSON: {"level":"error", "message":"DB connection failed"}
{namespace="ftm-dev", container="backend"} 
| json 
| level="error"

# Count errors per minute
count_over_time({namespace="ftm-dev"} | json | level="error" [1m])
```

#### 2.6. Rate queries

```logql
# Log lines per second
rate({namespace="ftm-dev"}[5m])

# Error logs per second
rate({namespace="ftm-dev"} |~ "error" [5m])

# Top 5 pods by log volume
topk(5, sum by (pod) (rate({namespace="ftm-dev"}[5m])))
```

### 3. Live Tailing

```
1. Enter query: {namespace="ftm-dev"}
2. Click "Live" button (gÃ³c pháº£i)
3. Logs sáº½ stream real-time
4. Click "Stop" Ä‘á»ƒ dá»«ng
```

### 4. Context - Xem logs xung quanh

```
1. Click vÃ o 1 log line
2. Click "Show context"
3. Tháº¥y 10 dÃ²ng trÆ°á»›c + sau log Ä‘Ã³
```

### 5. Log Formatting

**Switch view:**
- **Table**: Structured columns (time, labels, log)
- **Logs**: Raw log lines
- **JSON**: Pretty-printed JSON

**Tip:** Click vÃ o log line â†’ Labels â†’ Click label value Ä‘á»ƒ filter nhanh

---

## ğŸ” Sá»­ dá»¥ng Traces (Tempo)

### 1. Prerequisites

**Backend pháº£i instrument vá»›i OpenTelemetry:**

```csharp
// Program.cs - .NET Backend
builder.Services.AddOpenTelemetry()
    .WithTracing(tracerProvider =>
    {
        tracerProvider
            .AddAspNetCoreInstrumentation()
            .AddHttpClientInstrumentation()
            .AddSqlClientInstrumentation()
            .AddOtlpExporter(options =>
            {
                options.Endpoint = new Uri("http://tempo.monitoring.svc.cluster.local:4317");
            });
    });
```

### 2. Explore Traces

**Navigation:** Explore (ğŸ§­) â†’ Chá»n "Tempo" á»Ÿ dropdown

### 3. Search Traces

#### 3.1. Search by Service Name

```
Service Name: ftm-backend
Operation: /api/users/login
```

#### 3.2. Search by Tags

```
Tags:
  http.method = POST
  http.status_code = 500
  http.url = /api/order/create
```

#### 3.3. Search by Duration

```
Duration: > 1000ms  (tÃ¬m requests cháº­m hÆ¡n 1 giÃ¢y)
```

### 4. Analyze Trace

**Khi click vÃ o 1 trace:**

```
â”œâ”€â”€ HTTP POST /api/order/create [2.3s total]
    â”œâ”€â”€ Database Query: SELECT * FROM Orders [800ms]
    â”œâ”€â”€ HTTP Call: Payment Gateway [1.2s]  â† SLOW!
    â”œâ”€â”€ Database Insert: INSERT INTO Orders [100ms]
    â””â”€â”€ Cache Set: Redis [50ms]
```

**Insights:**
- **Flamegraph**: Visual timeline
- **Spans**: Individual operations
- **Duration**: Each span time
- **Tags**: Metadata (SQL query, HTTP status, etc.)

### 5. Correlate Logs with Traces

**Náº¿u backend log trace_id:**

```json
{"level":"error", "message":"Payment failed", "trace_id":"abc123xyz"}
```

**Trong Loki â†’ Click trace_id â†’ Jump to Tempo trace**

---

## ğŸ“Š Táº¡o Custom Dashboards

### 1. Create New Dashboard

```
1. Dashboards (â˜°) â†’ New Dashboard
2. Add Panel â†’ Add Visualization
3. Select Datasource: Prometheus
4. Enter Query
5. Customize Panel
6. Save Dashboard
```

### 2. Example: FTM Backend Dashboard

#### Panel 1: Request Rate

```
Title: HTTP Request Rate
Query: sum(rate(http_requests_total{namespace="ftm-dev", service="ftm-backend"}[5m]))
Visualization: Graph (Time series)
Unit: requests/sec
```

#### Panel 2: Error Rate

```
Title: 5xx Error Rate
Query: sum(rate(http_requests_total{namespace="ftm-dev", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="ftm-dev"}[5m])) * 100
Visualization: Stat
Unit: percent (0-100)
Thresholds: 
  Green: 0-1%
  Yellow: 1-5%
  Red: >5%
```

#### Panel 3: Response Time

```
Title: P95 Response Time
Query: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="ftm-dev"}[5m])) by (le))
Visualization: Graph
Unit: seconds
```

#### Panel 4: CPU Usage

```
Title: Backend CPU Usage
Query: sum(rate(container_cpu_usage_seconds_total{namespace="ftm-dev", pod=~"ftm-backend.*"}[5m])) by (pod)
Visualization: Graph (Stacked area)
Unit: cores
```

#### Panel 5: Memory Usage

```
Title: Backend Memory Usage
Query: sum(container_memory_working_set_bytes{namespace="ftm-dev", pod=~"ftm-backend.*"}) by (pod)
Visualization: Graph (Lines)
Unit: bytes
```

#### Panel 6: Pod Status

```
Title: Running Pods
Query: sum(kube_pod_status_phase{namespace="ftm-dev", pod=~"ftm-backend.*", phase="Running"})
Visualization: Stat (Big number)
```

#### Panel 7: Recent Logs (Loki)

```
Datasource: Loki
Query: {namespace="ftm-dev", container="backend"} |~ "error|exception"
Visualization: Logs
Show: Last 50 lines
```

### 3. Dashboard Variables

**Táº¡o dropdown Ä‘á»ƒ chá»n namespace:**

```
1. Dashboard Settings (âš™ï¸) â†’ Variables â†’ Add Variable
2. Name: namespace
3. Type: Query
4. Datasource: Prometheus
5. Query: label_values(kube_pod_info, namespace)
6. Save
```

**DÃ¹ng trong queries:**

```promql
sum(rate(container_cpu_usage_seconds_total{namespace="$namespace"}[5m]))
```

### 4. Dashboard Links

**Link giá»¯a cÃ¡c dashboards:**

```
1. Dashboard Settings â†’ Links â†’ Add Link
2. Type: Dashboard
3. Target: FTM Backend Dashboard
4. Icon: external link
```

### 5. Time Variables

```promql
# Automatic time range in query
rate(http_requests_total[5m])

# Use dashboard time range
rate(http_requests_total[$__range])
```

### 6. Annotations (Mark events)

```
1. Dashboard â†’ Settings â†’ Annotations â†’ Add Annotation
2. Name: Deployments
3. Datasource: Prometheus
4. Query: changes(kube_deployment_status_observed_generation{namespace="ftm-dev"}[5m]) > 0
```

Sáº½ show vertical line khi cÃ³ deployment má»›i.

### 7. Export & Import Dashboard

**Export:**
```
Dashboard Settings â†’ JSON Model â†’ Copy to Clipboard
Save to file: ftm-backend-dashboard.json
```

**Import:**
```
Dashboards â†’ Import â†’ Upload JSON file
```

---

## ğŸš¨ Alert Management

### 1. View Active Alerts

```
Alerting (ğŸ””) â†’ Alert Rules
```

### 2. Custom Alert Rules (via Prometheus)

**File:** `Infrastructure/observability/prometheus/alert-rules.yaml`

**Example: High Memory Alert**

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ftm-custom-alerts
  namespace: monitoring
spec:
  groups:
  - name: ftm-backend
    interval: 30s
    rules:
    - alert: BackendHighMemory
      expr: |
        sum(container_memory_working_set_bytes{namespace="ftm-dev", pod=~"ftm-backend.*"})
        / sum(container_spec_memory_limit_bytes{namespace="ftm-dev", pod=~"ftm-backend.*"})
        > 0.9
      for: 5m
      labels:
        severity: warning
        service: ftm-backend
      annotations:
        summary: "Backend memory usage > 90%"
        description: "Backend pod {{ $labels.pod }} is using {{ $value | humanizePercentage }} of memory limit"
```

**Apply:**
```powershell
kubectl apply -f alert-rules.yaml
```

### 3. Silence Alerts

```
1. Alerting â†’ Silences â†’ New Silence
2. Matcher: alertname = BackendHighMemory
3. Duration: 2 hours
4. Comment: "Maintenance window"
5. Create
```

### 4. Alert Notification Channels

**Configured:** Gmail (via Alertmanager)

**Add Slack (Example):**

```yaml
# alertmanager-config.yaml
receivers:
  - name: 'slack-alerts'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#alerts'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

route:
  routes:
    - match:
        severity: critical
      receiver: slack-alerts
      continue: true
```

---

## ğŸ”§ Troubleshooting vá»›i Observability

### Scenario 1: Backend tráº£ vá» 500 error

**Step 1: Check metrics - CÃ³ spike errors khÃ´ng?**

```promql
# Grafana â†’ Explore â†’ Prometheus
rate(http_requests_total{namespace="ftm-dev", status="500"}[5m])
```

**Step 2: Check logs - Lá»—i gÃ¬?**

```logql
# Grafana â†’ Explore â†’ Loki
{namespace="ftm-dev", container="backend"} |~ "(?i)error|exception"
```

**Step 3: Check traces - Request nÃ o cháº­m?**

```
Grafana â†’ Explore â†’ Tempo
Search: http.status_code = 500
```

**Step 4: Correlate - TÃ¬m trace_id trong logs**

```logql
{namespace="ftm-dev"} | json | trace_id="abc123xyz"
```

### Scenario 2: Pod restart liÃªn tá»¥c

**Step 1: Check restart count**

```promql
kube_pod_container_status_restarts_total{namespace="ftm-dev"}
```

**Step 2: Check resource limits**

```promql
# Memory usage vs limit
container_memory_working_set_bytes{namespace="ftm-dev", pod="ftm-backend-xxx"}
/ container_spec_memory_limit_bytes{namespace="ftm-dev", pod="ftm-backend-xxx"}
```

**Step 3: Check logs before crash**

```powershell
# Kubectl - logs from previous crashed container
kubectl logs -n ftm-dev ftm-backend-xxx --previous
```

**Step 4: Check OOMKill events**

```logql
{namespace="ftm-dev"} |~ "OOMKilled|Out of memory"
```

### Scenario 3: Slow API response

**Step 1: Check P95 latency**

```promql
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket{namespace="ftm-dev"}[5m])) by (le, endpoint)
)
```

**Step 2: Find slow traces**

```
Tempo â†’ Search
Duration: > 2000ms
Service: ftm-backend
```

**Step 3: Analyze spans trong trace**

```
Click trace â†’ Flamegraph
Identify slowest span (e.g., Database query 1.8s)
```

**Step 4: Optimize code/query**

### Scenario 4: High CPU usage

**Step 1: Which pod?**

```promql
topk(5, 
  sum(rate(container_cpu_usage_seconds_total{namespace="ftm-dev"}[5m])) by (pod)
)
```

**Step 2: When did it start?**

```
Grafana â†’ Thay Ä‘á»•i time range â†’ Last 24 hours
Identify spike time
```

**Step 3: Correlate vá»›i deployment**

```
Dashboard â†’ Annotations (deployment events)
Check náº¿u spike trÃ¹ng vá»›i deployment má»›i
```

**Step 4: Profile application**

```csharp
// Enable diagnostic profiling endpoint
app.MapGet("/debug/pprof", async context => {
    // CPU profile, memory dump, etc.
});
```

---

## ğŸ’¡ Best Practices

### 1. Metrics Naming

**Follow Prometheus conventions:**

```
# GOOD
http_requests_total{method="GET", status="200"}
http_request_duration_seconds{endpoint="/api/users"}

# BAD
HTTPRequests
RequestDuration_ms
```

### 2. Label Cardinality

**âŒ Avoid high-cardinality labels:**

```promql
# BAD - user_id has millions of values
http_requests_total{user_id="12345"}

# GOOD - Use predefined categories
http_requests_total{user_tier="premium"}
```

### 3. Query Performance

**Use recording rules cho expensive queries:**

```yaml
# prometheus-rules.yaml
groups:
  - name: recorded
    interval: 30s
    rules:
      - record: job:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (job)
```

**DÃ¹ng trong dashboard:**
```promql
job:http_requests:rate5m{job="ftm-backend"}
```

### 4. Log Levels

**Structure logs properly:**

```csharp
// Backend logging
_logger.LogInformation("User {UserId} logged in", userId);
_logger.LogWarning("Payment retry attempt {Attempt}", attempt);
_logger.LogError(exception, "Database connection failed for {Operation}", operation);
```

**Benefits:**
- Structured logs â†’ Easy to parse in Loki
- Proper levels â†’ Easy to filter
- Context variables â†’ Better debugging

### 5. Trace Sampling

**Don't trace everything - Sample strategically:**

```csharp
builder.Services.AddOpenTelemetry()
    .WithTracing(tracerProvider =>
    {
        tracerProvider.SetSampler(new TraceIdRatioBasedSampler(0.1)); // 10% sampling
    });
```

### 6. Dashboard Organization

```
Create folder structure:
â”œâ”€â”€ FTM Application
â”‚   â”œâ”€â”€ Backend Overview
â”‚   â”œâ”€â”€ Frontend Overview
â”‚   â”œâ”€â”€ Database
â”‚   â””â”€â”€ External APIs
â”œâ”€â”€ Infrastructure
â”‚   â”œâ”€â”€ Kubernetes Cluster
â”‚   â”œâ”€â”€ Nodes
â”‚   â””â”€â”€ Storage
â””â”€â”€ Business Metrics
    â”œâ”€â”€ Orders
    â”œâ”€â”€ Users
    â””â”€â”€ Revenue
```

### 7. Alert Fatigue Prevention

**Rules for good alerts:**
1. **Actionable**: Alert chá»‰ khi cáº§n human intervention
2. **Meaningful**: Include context trong description
3. **Grouped**: Group related alerts Ä‘á»ƒ trÃ¡nh spam
4. **Tuned**: Adjust thresholds Ä‘á»ƒ giáº£m false positives

**Example:**

```yaml
# âŒ BAD - Alert on every error
- alert: AnyError
  expr: rate(http_requests_total{status="500"}[1m]) > 0

# âœ… GOOD - Alert on sustained high error rate
- alert: HighErrorRate
  expr: |
    sum(rate(http_requests_total{status=~"5.."}[5m])) 
    / sum(rate(http_requests_total[5m])) 
    > 0.05
  for: 10m  # Must persist 10 minutes
```

### 8. Retention Policies

**Balance between cost and usefulness:**

```yaml
# Prometheus - Short-term, high-resolution
retention: 7d

# Loki - Medium-term logs
retention_period: 168h  # 7 days

# Tempo - Short-term traces (expensive)
retention: 72h  # 3 days

# Long-term: Use Thanos/Cortex for Prometheus
# Export to Azure Blob Storage for Loki
```

### 9. Security

**Protect Grafana:**

```yaml
# grafana.ini
[auth.anonymous]
enabled = false  # Disable anonymous access

[auth.basic]
enabled = true

[security]
admin_password = <strong-password>
secret_key = <random-secret-key>
```

**Use RBAC:**
```
1. Configuration â†’ Users â†’ Add User
2. Role: Viewer (chá»‰ xem dashboards)
3. Or: Editor (create dashboards)
```

### 10. Documentation

**Document dashboards:**

```
1. Dashboard Settings â†’ Description
2. Add Markdown text panel vá»›i:
   - Purpose cá»§a dashboard
   - CÃ¡c metrics quan trá»ng
   - Links tá»›i runbooks
   - Contact team
```

---

## ğŸ“š Advanced Topics

### 1. Custom Metrics tá»« Application

**.NET Backend Example:**

```csharp
// Startup.cs
services.AddSingleton<IMetrics>(_ => 
{
    var metrics = new MetricServer(port: 9090);
    metrics.Start();
    return Metrics.DefaultRegistry;
});

// OrderController.cs
private readonly Counter _orderCounter = Metrics.CreateCounter(
    "ftm_orders_total", 
    "Total orders created",
    new CounterConfiguration { LabelNames = new[] { "status" } }
);

[HttpPost]
public async Task<IActionResult> CreateOrder(Order order)
{
    // ... business logic ...
    _orderCounter.WithLabels(order.Status).Inc();
    return Ok();
}
```

**Query trong Grafana:**

```promql
rate(ftm_orders_total[5m])
sum(ftm_orders_total) by (status)
```

### 2. LogQL Advanced Queries

**Extract vÃ  aggregate values tá»« logs:**

```logql
# Count errors by endpoint
sum by (endpoint) (
  count_over_time(
    {namespace="ftm-dev"} 
    | json 
    | level="error" 
    [5m]
  )
)

# Average response time tá»« logs
avg_over_time(
  {namespace="ftm-dev"} 
  | json 
  | unwrap duration 
  [5m]
)
```

### 3. Tempo Service Graph

**Enable trong Grafana:**

```
1. Explore â†’ Tempo
2. Tab "Service Graph"
3. See visual map of service dependencies
```

**Shows:**
- Request flow: Frontend â†’ Backend â†’ Database
- Error rates per connection
- Latency per hop

### 4. Distributed Tracing Context Propagation

**Frontend â†’ Backend trace propagation:**

```typescript
// Frontend (React)
const response = await fetch('/api/order', {
  headers: {
    'traceparent': generateTraceParent(), // W3C Trace Context
  }
});
```

```csharp
// Backend (.NET)
app.Use(async (context, next) =>
{
    // Extract traceparent header
    var traceparent = context.Request.Headers["traceparent"];
    // Propagate to downstream calls...
    await next();
});
```

---

## ğŸ“ Learning Resources

### PromQL
- **Official Docs**: https://prometheus.io/docs/prometheus/latest/querying/basics/
- **PromQL Cheat Sheet**: https://promlabs.com/promql-cheat-sheet/
- **Query Examples**: https://prometheus.io/docs/prometheus/latest/querying/examples/

### LogQL
- **Official Docs**: https://grafana.com/docs/loki/latest/logql/
- **Log Queries**: https://grafana.com/docs/loki/latest/logql/log_queries/
- **Metric Queries**: https://grafana.com/docs/loki/latest/logql/metric_queries/

### Grafana
- **Fundamentals**: https://grafana.com/tutorials/grafana-fundamentals/
- **Dashboard Best Practices**: https://grafana.com/docs/grafana/latest/best-practices/best-practices-for-creating-dashboards/

### OpenTelemetry
- **.NET Instrumentation**: https://opentelemetry.io/docs/instrumentation/net/
- **Automatic Instrumentation**: https://github.com/open-telemetry/opentelemetry-dotnet-instrumentation

---

## ğŸ“ Support

**Issues vá»›i Observability Stack:**
- GitHub Issues: https://github.com/yourorg/Infrastructure/issues
- Team Contact: devops@yourcompany.com
- Documentation: `Infrastructure/observability/README.md`

**Monitoring Health:**
```powershell
# Check all monitoring pods
kubectl get pods -n monitoring

# Grafana status
kubectl get ingress -n monitoring prometheus-grafana
```

---

**âœ… HoÃ n thÃ nh Usage Guide!**

BÃ¢y giá» báº¡n Ä‘Ã£ biáº¿t cÃ¡ch sá»­ dá»¥ng full observability stack. Happy monitoring! ğŸ“ŠğŸ”ğŸ“ˆ
