# ğŸ“š HÆ°á»›ng dáº«n CÃ i Ä‘áº·t Observability Stack - AKS

> **TÃ i liá»‡u:** HÆ°á»›ng dáº«n tá»«ng bÆ°á»›c cÃ i Ä‘áº·t full observability stack (Prometheus, Grafana, Loki, Tempo, Fluent Bit, Alertmanager)  
> **MÃ´i trÆ°á»ng:** Azure Kubernetes Service (AKS)  
> **Cáº­p nháº­t:** November 2025

---

## ğŸ“‹ Má»¥c lá»¥c

1. [YÃªu cáº§u há»‡ thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
2. [Kiáº¿n trÃºc tá»•ng quan](#-kiáº¿n-trÃºc-tá»•ng-quan)
3. [CÃ i Ä‘áº·t Prometheus + Grafana](#-bÆ°á»›c-1-cÃ i-Ä‘áº·t-prometheus--grafana)
4. [CÃ i Ä‘áº·t Loki](#-bÆ°á»›c-2-cÃ i-Ä‘áº·t-loki)
5. [CÃ i Ä‘áº·t Tempo](#-bÆ°á»›c-3-cÃ i-Ä‘áº·t-tempo)
6. [CÃ i Ä‘áº·t Fluent Bit](#-bÆ°á»›c-4-cÃ i-Ä‘áº·t-fluent-bit)
7. [Cáº¥u hÃ¬nh Alertmanager](#-bÆ°á»›c-5-cáº¥u-hÃ¬nh-alertmanager)
8. [Cáº¥u hÃ¬nh DNS](#-bÆ°á»›c-6-cáº¥u-hÃ¬nh-dns)
9. [XÃ¡c thá»±c cÃ i Ä‘áº·t](#-bÆ°á»›c-7-xÃ¡c-thá»±c-cÃ i-Ä‘áº·t)
10. [Troubleshooting](#-troubleshooting)

---

## ğŸ”§ YÃªu cáº§u há»‡ thá»‘ng

### Kubernetes Cluster
- **AKS Cluster**: 1.28+ (tested on 1.31.13)
- **Node Pool**: Standard_D2s_v3 hoáº·c lá»›n hÆ¡n
- **RAM**: Minimum 8GB per node (recommended 16GB)
- **CPU**: Minimum 2 vCPU per node
- **Storage**: Azure Managed Disks (Premium_LRS)

### Resource Requirements

| Component | CPU Request | Memory Request | Storage |
|-----------|-------------|----------------|---------|
| Prometheus | 100m | 256Mi | 10Gi |
| Grafana | 100m | 256Mi | 5Gi |
| Alertmanager | 50m | 128Mi | 2Gi |
| Loki | 100m | 256Mi | 10Gi |
| Tempo | 100m | 256Mi | 10Gi |
| Fluent Bit | 50m/node | 64Mi/node | - |
| **TOTAL** | ~600m + 50m/node | ~1200Mi + 64Mi/node | ~37Gi |

**VÃ­ dá»¥:** 1 node D2s_v3 (2 vCPU, 8GB RAM) = ~7GB allocatable  
â†’ Äá»§ cho dev environment vá»›i 1 node

### Tools cáº§n cÃ i Ä‘áº·t
```bash
# PowerShell trÃªn Windows
winget install Kubernetes.kubectl
winget install Helm.Helm

# Hoáº·c Chocolatey
choco install kubernetes-cli helm

# Kiá»ƒm tra version
kubectl version --client
helm version
```

### Access Requirements
- **kubectl** configured vá»›i AKS cluster
- **Helm 3.x** installed
- **Ingress Controller** (nginx) Ä‘Ã£ deploy
- **DNS Control** (Ä‘á»ƒ táº¡o A records)

---

## ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBSERVABILITY STACK                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Prometheus  â”‚    â”‚     Loki     â”‚    â”‚    Tempo     â”‚  â”‚
â”‚  â”‚   (Metrics)  â”‚    â”‚    (Logs)    â”‚    â”‚   (Traces)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                   â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                             â”‚                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                    â”‚    Grafana      â”‚                     â”‚
â”‚                    â”‚  (Visualization)â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                             â”‚                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                    â”‚ Alertmanager    â”‚                     â”‚
â”‚                    â”‚ (Email Alerts)  â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Fluent Bit (DaemonSet)                  â”‚  â”‚
â”‚  â”‚         Collects logs from all pods                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Ingress (HTTPS)
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  grafana.domain.com  â”‚
                â”‚    loki.domain.com   â”‚
                â”‚   tempo.domain.com   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ BÆ¯á»šC 1: CÃ i Ä‘áº·t Prometheus + Grafana

### 1.1. Chuáº©n bá»‹ Helm Repository

```powershell
# Add Prometheus Community Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Verify repo
helm search repo prometheus-community/kube-prometheus-stack
```

### 1.2. Táº¡o Namespace

```powershell
kubectl create namespace monitoring
kubectl label namespace monitoring name=monitoring
```

### 1.3. Review Configuration

File: `Infrastructure/observability/prometheus/values.yaml`

**CÃ¡c cáº¥u hÃ¬nh quan trá»ng:**

```yaml
# Prometheus Server
prometheus:
  prometheusSpec:
    retention: 7d              # Giá»¯ metrics 7 ngÃ y
    storageSpec:
      volumeClaimTemplate:
        spec:
          resources:
            requests:
              storage: 10Gi    # 10GB storage
    
    resources:
      requests:
        cpu: 100m
        memory: 256Mi          # Tá»‘i Æ°u cho dev

# Grafana
grafana:
  adminPassword: "Admin@123456"  # âš ï¸ Äá»”I SAU KHI CÃ€I!
  ingress:
    enabled: true
    hosts:
      - grafana.longops.io.vn  # ğŸ”§ Äá»”I DOMAIN Cá»¦A Báº N
```

**ğŸ“ Sá»­a file values.yaml:**

```powershell
# Má»Ÿ file
code E:\AKS-DEMO\Infrastructure\observability\prometheus\values.yaml

# TÃ¬m vÃ  sá»­a:
# 1. Line ~68: grafana.longops.io.vn â†’ YOUR_DOMAIN
# 2. Line ~43: adminPassword â†’ YOUR_STRONG_PASSWORD (náº¿u muá»‘n)
```

### 1.4. Deploy Prometheus Stack

```powershell
cd E:\AKS-DEMO\Infrastructure\observability\prometheus

helm upgrade --install prometheus prometheus-community/kube-prometheus-stack `
  --namespace monitoring `
  --create-namespace `
  --values values.yaml `
  --wait `
  --timeout 10m
```

**Output mong Ä‘á»£i:**
```
Release "prometheus" does not exist. Installing it now.
NAME: prometheus
LAST DEPLOYED: Mon Nov 25 14:30:00 2025
NAMESPACE: monitoring
STATUS: deployed
REVISION: 1
```

### 1.5. Verify Deployment

```powershell
# Check pods
kubectl get pods -n monitoring

# Expected output:
# NAME                                                     READY   STATUS
# prometheus-prometheus-prometheus-0                      3/3     Running
# prometheus-grafana-xxxxx-xxxxx                          3/3     Running
# prometheus-kube-state-metrics-xxxxx-xxxxx               1/1     Running
# prometheus-prometheus-node-exporter-xxxxx               1/1     Running
# prometheus-prometheus-operator-xxxxx-xxxxx              1/1     Running

# Check services
kubectl get svc -n monitoring

# Check PVC
kubectl get pvc -n monitoring
```

**Thá»i gian deploy:** ~5-10 phÃºt (pull images + create PVs)

### 1.6. Access Grafana

**Option A: Port Forward (Test local)**
```powershell
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Truy cáº­p: http://localhost:3000
# Username: admin
# Password: Admin@123456 (hoáº·c password báº¡n Ä‘Ã£ Ä‘á»•i)
```

**Option B: Ingress (Production)**
```powershell
# Get Ingress IP
kubectl get ingress -n monitoring prometheus-grafana

# Output:
# NAME                 CLASS   HOSTS                   ADDRESS          PORTS
# prometheus-grafana   nginx   grafana.longops.io.vn   4.144.199.99     80, 443

# Sau khi setup DNS (BÆ°á»›c 6):
# Truy cáº­p: https://grafana.longops.io.vn
```

---

## ğŸ“¦ BÆ¯á»šC 2: CÃ i Ä‘áº·t Loki

### 2.1. ThÃªm Grafana Helm Repo

```powershell
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
```

### 2.2. Review Configuration

File: `Infrastructure/observability/loki/values.yaml`

**Cáº¥u hÃ¬nh SingleBinary mode (tiáº¿t kiá»‡m resources):**

```yaml
deploymentMode: SingleBinary  # Single pod = Ã­t resource hÆ¡n
loki:
  commonConfig:
    replication_factor: 1     # KhÃ´ng replicate (dev only)
  storage:
    type: filesystem          # Store trÃªn disk
  schemaConfig:
    configs:
      - from: "2024-01-01"
        store: tsdb
        index:
          period: 24h
  limits_config:
    retention_period: 168h    # 7 days

gateway:
  ingress:
    enabled: true
    hosts:
      - host: loki.longops.io.vn  # ğŸ”§ Äá»”I DOMAIN
```

**ğŸ“ Sá»­a domain:**
```powershell
code E:\AKS-DEMO\Infrastructure\observability\loki\values.yaml
# Line ~83: loki.longops.io.vn â†’ YOUR_DOMAIN
```

### 2.3. Deploy Loki

```powershell
cd E:\AKS-DEMO\Infrastructure\observability\loki

helm upgrade --install loki grafana/loki `
  --namespace monitoring `
  --values values.yaml `
  --wait `
  --timeout 10m
```

### 2.4. Verify Loki

```powershell
kubectl get pods -n monitoring -l app.kubernetes.io/name=loki

# Expected:
# loki-0                    1/1     Running
# loki-gateway-xxxxx        1/1     Running

# Test Loki API
kubectl port-forward -n monitoring svc/loki-gateway 3100:80

# Trong terminal khÃ¡c:
curl http://localhost:3100/ready
# Output: ready
```

---

## ğŸ“¦ BÆ¯á»šC 3: CÃ i Ä‘áº·t Tempo

### 3.1. Review Configuration

File: `Infrastructure/observability/tempo/values.yaml`

**Cáº¥u hÃ¬nh Distributed Tracing:**

```yaml
tempo:
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
  
  retention: 168h  # 7 days
  
  # Receivers for different protocols
  receivers:
    otlp:
      protocols:
        http:
          endpoint: 0.0.0.0:4318  # OpenTelemetry HTTP
        grpc:
          endpoint: 0.0.0.0:4317  # OpenTelemetry gRPC
    jaeger:
      protocols:
        thrift_http:
          endpoint: 0.0.0.0:14268
        grpc:
          endpoint: 0.0.0.0:14250
    zipkin:
      endpoint: 0.0.0.0:9411

ingress:
  enabled: true
  hosts:
    - host: tempo.longops.io.vn  # ğŸ”§ Äá»”I DOMAIN
```

**ğŸ“ Sá»­a domain:**
```powershell
code E:\AKS-DEMO\Infrastructure\observability\tempo\values.yaml
# Line ~54: tempo.longops.io.vn â†’ YOUR_DOMAIN
```

### 3.2. Deploy Tempo

```powershell
cd E:\AKS-DEMO\Infrastructure\observability

helm upgrade --install tempo grafana/tempo `
  --namespace monitoring `
  --values tempo/values.yaml `
  --wait `
  --timeout 10m
```

### 3.3. Verify Tempo

```powershell
kubectl get pods -n monitoring -l app.kubernetes.io/name=tempo

# Expected:
# tempo-xxxxx-xxxxx    1/1     Running

# Test Tempo ready
kubectl port-forward -n monitoring svc/tempo 3100:3100
curl http://localhost:3100/ready
```

---

## ğŸ“¦ BÆ¯á»šC 4: CÃ i Ä‘áº·t Fluent Bit

### 4.1. Review Configuration

File: `Infrastructure/observability/fluent-bit/values.yaml`

**DaemonSet - Cháº¡y trÃªn má»i node:**

```yaml
config:
  inputs: |
    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     5MB

  outputs: |
    [OUTPUT]
        Name   loki
        Match  *
        Host   loki-gateway.monitoring.svc.cluster.local
        Port   80
        Labels job=fluentbit, container=$kubernetes['container_name']
```

### 4.2. Deploy Fluent Bit

```powershell
helm repo add fluent https://fluent.github.io/helm-charts
helm repo update

cd E:\AKS-DEMO\Infrastructure\observability

helm upgrade --install fluent-bit fluent/fluent-bit `
  --namespace monitoring `
  --values fluent-bit/values.yaml `
  --wait
```

### 4.3. Verify Fluent Bit

```powershell
# Should have 1 pod per node
kubectl get pods -n monitoring -l app.kubernetes.io/name=fluent-bit -o wide

# Check logs
kubectl logs -n monitoring -l app.kubernetes.io/name=fluent-bit --tail=50

# Should see:
# [info] [output:loki:loki.0] loki_gateway.monitoring.svc.cluster.local:80, HTTP status=204
```

---

## ğŸ“¦ BÆ¯á»šC 5: Cáº¥u hÃ¬nh Alertmanager

### 5.1. Táº¡o Gmail App Password

**âš ï¸ YÃŠU Cáº¦U: Gmail account vá»›i 2FA enabled**

1. **Báº­t 2-Factor Authentication:**
   - Truy cáº­p: https://myaccount.google.com/security
   - Security â†’ 2-Step Verification â†’ Báº­t

2. **Táº¡o App Password:**
   - Truy cáº­p: https://myaccount.google.com/apppasswords
   - App name: "AKS Alertmanager"
   - Click "Generate"
   - **Copy 16-kÃ½ tá»± password** (vÃ­ dá»¥: `abcd efgh ijkl mnop`)

### 5.2. Cáº¥u hÃ¬nh Alertmanager

File: `Infrastructure/observability/prometheus/alertmanager-gmail-config.yaml`

**ğŸ“ Sá»­a thÃ´ng tin:**

```powershell
code E:\AKS-DEMO\Infrastructure\observability\prometheus\alertmanager-gmail-config.yaml
```

**Cáº§n sá»­a 3 chá»—:**

```yaml
# 1. Secret - Line 12
data:
  smtp-password: YWJjZCBlZmdoIGlqa2wgbW5vcA==  # Base64 cá»§a app password
  # Generate: [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes("abcd efgh ijkl mnop"))

# 2. ConfigMap - Line 35
smtp_auth_username: 'your-email@gmail.com'  # Email cá»§a báº¡n

# 3. ConfigMap - Line 52
receivers:
  - name: 'critical-alerts'
    email_configs:
      - to: 'your-alert-email@gmail.com'  # Email nháº­n alert
```

**Convert password sang Base64:**

```powershell
# Replace 'your-app-password' vá»›i 16-kÃ½ tá»± tá»« Gmail
$password = 'abcd efgh ijkl mnop'
$base64 = [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes($password))
Write-Host "Base64: $base64"
```

### 5.3. Apply Alertmanager Config

```powershell
cd E:\AKS-DEMO\Infrastructure\observability\prometheus

# Apply secret vÃ  config
kubectl apply -f alertmanager-gmail-config.yaml

# Restart Alertmanager to load config
kubectl rollout restart statefulset -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager

# Check logs
kubectl logs -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager-0 -c alertmanager --tail=50
```

### 5.4. Apply Custom Alert Rules

```powershell
cd E:\AKS-DEMO\Infrastructure\observability\prometheus

kubectl apply -f alert-rules.yaml

# Verify
kubectl get prometheusrules -n monitoring ftm-alerts
```

**Alert rules bao gá»“m:**
- FTMBackendDown (critical)
- FTMBackendHighErrorRate (warning)
- FTMBackendHighMemory (warning)
- FTMFrontendDown (critical)
- NodeHighMemoryUsage (critical)
- PodCrashLooping (warning)

### 5.5. Test Alerts

```powershell
# Access Alertmanager UI
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093

# Truy cáº­p: http://localhost:9093
# Check: Status â†’ Receivers â†’ "critical-alerts"

# Test báº±ng cÃ¡ch scale down backend
kubectl scale deployment ftm-backend -n ftm-dev --replicas=0
# Äá»£i 2 phÃºt â†’ Sáº½ nháº­n email "FTMBackendDown"

# Scale back up
kubectl scale deployment ftm-backend -n ftm-dev --replicas=1
```

---

## ğŸ“¦ BÆ¯á»šC 6: Cáº¥u hÃ¬nh DNS

### 6.1. Get Ingress External IP

```powershell
kubectl get svc -n ingress-nginx ingress-nginx-controller

# Output:
# NAME                       TYPE           EXTERNAL-IP      PORT(S)
# ingress-nginx-controller   LoadBalancer   4.144.199.99     80:31189/TCP,443:32400/TCP
```

### 6.2. Táº¡o DNS A Records

**Náº¿u dÃ¹ng Azure DNS:**

```powershell
# Variables
$RESOURCE_GROUP = "rg-ftm-aks-dev"
$DNS_ZONE = "longops.io.vn"
$INGRESS_IP = "4.144.199.99"

# Create records
az network dns record-set a add-record `
  --resource-group $RESOURCE_GROUP `
  --zone-name $DNS_ZONE `
  --record-set-name grafana `
  --ipv4-address $INGRESS_IP

az network dns record-set a add-record `
  --resource-group $RESOURCE_GROUP `
  --zone-name $DNS_ZONE `
  --record-set-name loki `
  --ipv4-address $INGRESS_IP

az network dns record-set a add-record `
  --resource-group $RESOURCE_GROUP `
  --zone-name $DNS_ZONE `
  --record-set-name tempo `
  --ipv4-address $INGRESS_IP
```

**Náº¿u dÃ¹ng DNS provider khÃ¡c (Cloudflare, GoDaddy...):**

| Type | Name | Value | TTL |
|------|------|-------|-----|
| A | grafana | 4.144.199.99 | 300 |
| A | loki | 4.144.199.99 | 300 |
| A | tempo | 4.144.199.99 | 300 |

### 6.3. Verify DNS

```powershell
# Test DNS resolution
nslookup grafana.longops.io.vn 8.8.8.8
nslookup loki.longops.io.vn 8.8.8.8
nslookup tempo.longops.io.vn 8.8.8.8

# Test HTTP access
curl -I http://grafana.longops.io.vn
curl -I http://loki.longops.io.vn/ready
curl -I http://tempo.longops.io.vn/ready
```

---

## âœ… BÆ¯á»šC 7: XÃ¡c thá»±c cÃ i Ä‘áº·t

### 7.1. Check All Pods

```powershell
kubectl get pods -n monitoring

# All should be Running/Completed:
# prometheus-prometheus-prometheus-0                       3/3     Running
# prometheus-grafana-xxxxx-xxxxx                           3/3     Running
# prometheus-kube-state-metrics-xxxxx                      1/1     Running
# prometheus-prometheus-node-exporter-xxxxx                1/1     Running (per node)
# prometheus-prometheus-operator-xxxxx                     1/1     Running
# alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running
# loki-0                                                   1/1     Running
# loki-gateway-xxxxx-xxxxx                                 1/1     Running
# tempo-xxxxx-xxxxx                                        1/1     Running
# fluent-bit-xxxxx                                         1/1     Running (per node)
```

### 7.2. Check Resource Usage

```powershell
# Node resources
kubectl top node

# Pod resources
kubectl top pods -n monitoring --sort-by=memory
```

### 7.3. Check Storage

```powershell
kubectl get pvc -n monitoring

# Should see:
# prometheus-prometheus-prometheus-db-prometheus-prometheus-prometheus-0   10Gi
# loki-storage-loki-0                                                      10Gi
# tempo-storage-tempo-0                                                    10Gi
# grafana-storage                                                          5Gi
# alertmanager-storage-alertmanager-prometheus-...-0                       2Gi
```

### 7.4. Access Grafana

```powershell
# URL: https://grafana.longops.io.vn
# Username: admin
# Password: Admin@123456 (hoáº·c password báº¡n Ä‘Ã£ Ä‘á»•i)
```

**Verify trong Grafana:**

1. **Datasources:**
   - Configuration â†’ Data Sources
   - Should see: Prometheus (default), Loki, Tempo

2. **Pre-installed Dashboards:**
   - Dashboards â†’ Browse
   - Kubernetes / Compute Resources / Cluster
   - Kubernetes / Compute Resources / Namespace (Pods)
   - Node Exporter / Nodes

3. **Explore Metrics:**
   - Explore â†’ Prometheus
   - Query: `up` (shows all scraped targets)

4. **Explore Logs:**
   - Explore â†’ Loki
   - Query: `{namespace="ftm-dev"}`

5. **Alerts:**
   - Alerting â†’ Alert Rules
   - Should see custom rules from `alert-rules.yaml`

---

## ğŸ”§ Troubleshooting

### Issue 1: Pods Pending (Insufficient Resources)

**Symptoms:**
```
kubectl get pods -n monitoring
NAME                          READY   STATUS    RESTARTS   AGE
prometheus-prometheus-0       0/3     Pending   0          5m
```

**Diagnosis:**
```powershell
kubectl describe pod -n monitoring prometheus-prometheus-0

# Look for:
# Events:
#   Warning  FailedScheduling  ... Insufficient memory/cpu
```

**Solution:**
```powershell
# Check node resources
kubectl top node
kubectl describe node

# Option 1: Scale up node pool
az aks nodepool scale `
  --resource-group rg-ftm-aks-dev `
  --cluster-name aks-ftm-dev `
  --name pool2 `
  --node-count 2

# Option 2: Upgrade node VM size
# See: Infrastructure/observability/RESOURCE_REQUIREMENTS.md
```

### Issue 2: Prometheus PVC Stuck in Pending

**Symptoms:**
```
kubectl get pvc -n monitoring
NAME                                 STATUS    VOLUME   CAPACITY
prometheus-prometheus-db-...         Pending            
```

**Solution:**
```powershell
# Check StorageClass
kubectl get storageclass

# Should have 'default' or 'managed-premium'
# If not, create one:
kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: default
provisioner: disk.csi.azure.com
parameters:
  storageaccounttype: Premium_LRS
  kind: Managed
EOF
```

### Issue 3: Grafana 502 Bad Gateway

**Symptoms:**
```
curl https://grafana.longops.io.vn
# 502 Bad Gateway
```

**Diagnosis:**
```powershell
# Check Grafana pod
kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana

# Check Ingress
kubectl describe ingress -n monitoring prometheus-grafana
```

**Solution:**
```powershell
# Restart Grafana
kubectl rollout restart deployment -n monitoring prometheus-grafana

# Wait for ready
kubectl rollout status deployment -n monitoring prometheus-grafana
```

### Issue 4: Fluent Bit Not Sending Logs to Loki

**Symptoms:**
```
# No logs in Grafana Explore â†’ Loki
```

**Diagnosis:**
```powershell
kubectl logs -n monitoring -l app.kubernetes.io/name=fluent-bit --tail=100

# Look for errors:
# [error] [output:loki:loki.0] HTTP status=400
```

**Solution:**
```powershell
# Check Loki service
kubectl get svc -n monitoring loki-gateway

# Should be: loki-gateway.monitoring.svc.cluster.local:80

# Restart Fluent Bit
kubectl rollout restart daemonset -n monitoring fluent-bit

# Test Loki manually
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://loki-gateway.monitoring.svc.cluster.local/ready
```

### Issue 5: Alertmanager Not Sending Emails

**Symptoms:**
- Alerts firing in Prometheus
- No emails received

**Diagnosis:**
```powershell
# Check Alertmanager logs
kubectl logs -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager-0 -c alertmanager

# Look for:
# level=error msg="Notify for alerts failed" err="...authentication failed..."
```

**Common issues:**
1. **Wrong Gmail app password** â†’ Regenerate trong Google Account
2. **2FA not enabled** â†’ Enable 2FA first
3. **Base64 encoding wrong** â†’ Re-encode password:
   ```powershell
   $password = 'your-16-char-app-password'
   [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes($password))
   ```
4. **Email blocked by Gmail** â†’ Check Gmail security: https://myaccount.google.com/security

**Solution:**
```powershell
# Update secret vá»›i correct password
kubectl delete secret -n monitoring alertmanager-gmail-secret
kubectl create secret generic alertmanager-gmail-secret `
  --from-literal=smtp-password='your-correct-app-password' `
  -n monitoring

# Restart Alertmanager
kubectl rollout restart statefulset -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager
```

### Issue 6: High Memory Usage / OOMKilled

**Symptoms:**
```
kubectl get pods -n monitoring
NAME                          READY   STATUS      RESTARTS
prometheus-prometheus-0       2/3     OOMKilled   3
```

**Solution:**
```powershell
# Reduce retention period
# Edit values.yaml:
prometheus:
  prometheusSpec:
    retention: 3d  # Giáº£m tá»« 7d â†’ 3d

# Upgrade release
helm upgrade prometheus prometheus-community/kube-prometheus-stack `
  --namespace monitoring `
  --values prometheus/values.yaml `
  --reuse-values
```

---

## ğŸ“Š Resource Monitoring

### Check Overall Cluster Health

```powershell
# Node resources
kubectl top node

# Pod resources in monitoring namespace
kubectl top pods -n monitoring --sort-by=memory

# Persistent Volume usage
kubectl get pvc -n monitoring
kubectl exec -it -n monitoring prometheus-prometheus-prometheus-0 -c prometheus -- df -h /prometheus
```

### Expected Resource Usage (1 Node D2s_v3)

| Component | CPU | Memory | Comments |
|-----------|-----|--------|----------|
| Prometheus | 200-500m | 600-800Mi | Depends on scrape frequency |
| Grafana | 50-100m | 200-300Mi | Idle usage |
| Loki | 100-200m | 300-400Mi | Depends on log volume |
| Tempo | 50-100m | 200-300Mi | Low usage in dev |
| Fluent Bit | 50m | 64Mi | Per node |
| **TOTAL** | ~1-2 vCPU | ~3-4GB | Out of 7GB allocatable |

---

## ğŸ¯ Next Steps

Sau khi cÃ i Ä‘áº·t xong, tham kháº£o:

1. **[USAGE_GUIDE.md](./USAGE_GUIDE.md)** - HÆ°á»›ng dáº«n sá»­ dá»¥ng Grafana, táº¡o dashboards, query logs/metrics
2. **[README.md](./README.md)** - Tá»•ng quan architecture vÃ  concepts
3. **[RESOURCE_REQUIREMENTS.md](./RESOURCE_REQUIREMENTS.md)** - Chi tiáº¿t vá» resources vÃ  scaling

---

## ğŸ“š References

- **Prometheus Operator**: https://prometheus-operator.dev/
- **Grafana Loki**: https://grafana.com/docs/loki/latest/
- **Grafana Tempo**: https://grafana.com/docs/tempo/latest/
- **Fluent Bit**: https://docs.fluentbit.io/
- **Helm Charts**: 
  - kube-prometheus-stack: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
  - loki: https://github.com/grafana/loki/tree/main/production/helm/loki
  - tempo: https://github.com/grafana/helm-charts/tree/main/charts/tempo

---

**âœ… HoÃ n thÃ nh Installation Guide!**

Báº¡n Ä‘Ã£ cÃ³ má»™t observability stack Ä‘áº§y Ä‘á»§ trÃªn AKS. Tiáº¿p theo, há»c cÃ¡ch sá»­ dá»¥ng trong **USAGE_GUIDE.md**.
